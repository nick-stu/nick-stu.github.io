---
title:      "数据挖掘导论笔记(1): 数据与探索数据"
date:       2018-07-30 16:39:53
tags:
- 数据挖掘
- 机器学习
- 读书笔记
---
# 绪论
数据挖掘主要任务：预测建模、关联分析、聚类分析、异常检测  
# 数据
## 数据类型

属性和度量的概念  
关于属性的不同类型有：   
分类的（定性的）：标称、序数   
数值的（定量的）：区间、比率 

tips：只有非零值才重要的二元属性是非对称的二元属性  

数据集一般讨论三个特性：维度，稀疏性，分辨率  

## 数据质量

测量误差和数据收集误差、噪声、伪像  
此外还有精度、偏倚和准确度  
精度(precision)：（同一个量）重复测量值之间的接近程度  
偏倚(bias)：测量值和被测量值之间的系统的变差  
准确率(accuracy)：被测量值的测量值与实际值之间的接近度  
离群点，遗漏值和重复数据也影响数据质量  

## 数据预处理
数据预处理主要目的是选择分析需要的数据对象和属性以及改变/创建属性  

主要思想有聚集、抽样、维规约（[PCA](https://blog.csdn.net/watkinsong/article/details/38536463)、MDS等）、**特征子集选择**、特征创建、离散化和二元化、变量变换
>特征子集选择

包括嵌入式(embedded)、过滤式(filter)、包裹式(wrapper)  
除此之外，加权也是一种方法，有诸如fisherscore,relief等方法  
[淺談關於特徵選擇算法與Relief的實現](https://hk.saowen.com/a/76b83ad3b936220e65cc2181d30d796e830c6a3a7a4011dcf7ff228160e10233)

>特征创建

特征提取(feature extraction)：由原始数据创建新的特征集  
映射数据到新空间如FFT、PSD等  

>变量变换

这部分包含了一个常见的类型，即为标准化(standardization)和规范化（或归一化）(normalization)，例如z-score和min-max

----------


事实上，数据清洗和数据预处理过程都是特征工程的一部分。  
这里摘抄部分句子：  
>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。  
顾名思义，其本质是一项工程活动，目的是最大限度地从原始数据中提取特征以供算法和模型使用。

{% qnimg 10/1.jpg %}  
这里附上原链接：[机器学习中，有哪些特征选择的工程方法？](https://www.zhihu.com/question/28641663)

## 相似性和相异性的度量

记得之前在利用聚类算法优化一个项目精度时，改变了不同距离表示方法（曼哈顿、dtw、欧氏距离），当时把这概念称为“距离”。事实上，广义一点，官方一点的说法应该称为**邻近度(proximity)**，如何选择正确的邻近度度量是个重要的问题。
术语“距离”通常用作相异度的同义词。
>变换

通常，邻近度会被映射到[0,1]区间。或将相似度和相异度互相转化

> 简单属性的相似度和相异度

{% qnimg 10/2.png %}
> 数据对象之间的相异度

明可夫斯基距离(Minkowski distance)，常见的有曼哈顿距离、欧氏距离、上确界
>邻近度度量的例子

依据数据的离散与否，是否二元，非对称等选择合适的度量方法
简单匹配系数（SMC）、Jaccard系数、余弦相似度、广义Jaccard系数（又称Tanimoto系数，还有其他一种系数与其同名）、相关性（类似的有皮尔逊相关）
{% qnimg 10/3.png %}
相关性可视化
>邻近度计算问题

一些重要问题:

 1. 属性scale不同或相关
值域不同时标准化即可，但若属性之间相关，常会选择Mahalanobis距离
 2. 属性类型不同
将每个属性的相似度组合起来
 3. 属性权重不同
加权

# 探索数据
对数据进行初步研究，了解特殊性质，有助于选择合适的数据预处理和数据分析技术。

 1. 汇总统计
 2. 可视化技术
 3. OLAP和多维数据分析

本章的讨论常用Iris数据集，来自[加州大学欧文分校机器学习库](http://archive.ics.uci.edu/ml/index.php)
## 汇总分析
频率、众数（有时可用于检测遗漏值）、百分位数  
位置度量：均值（此外还有截断均值，即去掉最高最低的(p/2)%，之后求均值，可以减少离群值的影响）、中位数  
散布度量：极差和方差（方差离群值敏感）、绝对平均偏差（AAD）、中位数绝对偏差、四分位数极差  
> 对于多元连续变量的数据，散步更多地使用协方差矩阵(covariance matrix)。协方差的值接近于0表明两个变量不具有（线性）关系。不过对于相关性来说，相关矩阵更可取（correlation matrix）

## 可视化
>一般概念

表示（将数据映射到图形元素）、安排（顺序等）和选择
>技术

1.少量属性的可视化  
茎叶图（初中或者小学数学试卷考过的）、直方图（此外还有二维直方图）、饼图、百分位数图和经验**累计**分布函数、散布图（有助于判断属性之间关系、考察分类情况）  
盒状图
{% qnimg 10/4.png %}
2.可视化时间空间数据  
等高线图、曲面图、矢量场图
{% qnimg 10/5.png %}
低维切片图（用多个图表示），类似的还有动画  
3.可视化高维数据  
矩阵（可将矩阵转化为图像，可以便于观察）
{% qnimg 10/6.png %}
平行坐标系（需要注意安排好属性的顺序，交叉太多图形容易模糊不清）
{% qnimg 10/7.png %}
星形坐标
{% qnimg 10/8.png %}
chernoff脸（脑补一下小丸子她爷爷的脸就知道了）

Kaggle有个[Notebook](https://www.kaggle.com/benhamner/python-data-visualizations/notebook)演示了几种常见的可视化方法
>OLAP（联机分析处理）和多维数据分析
