---
title:      "数据挖掘导论笔记(2): 分类"
date:       2018-08-03 16:39:53
tags:
- 读书笔记
- 数据挖掘
- 机器学习
---

前言：4.6中 “比较分类器的方法” 一节中涉及不少统计学知识，值得一看  

----------


# 预备知识
类标签必须是离散的，这正是区分分类和回归的关键特征。  
>定义上，分类任务就是通过学习得到一个目标函数f，把每个属性集x映射到一个预先定义的类标号y

分类技术非常适合预测或描述二元或标称类型的数据集，对于序数分类不太有效。本章也只考虑二元的或标称类型的类标号。

# 一般方法
>分类法是一种根据输入数据集建立分类模型的系统方法  

包括决策树、基于规则的分类法、神经网络、支持向量机和朴素贝叶斯分类法等。  

模型达到的效果应该是**拟合**与**预测**（即泛化能力）  
衡量分类模型性能可以是混淆矩阵和准确率（accuracy） 
{% qnimg 12/1.png %}  
<center>混淆矩阵</center>

# 决策树归纳
## 工作原理
{% qnimg 12/2.png %}  
<center>哺乳动物分类问题的决策树</center>

## 如何建立
### Hunt算法
### 设计问题

 1. 如何分裂训练记录
 2. 如何停止分裂
 

## 表示属性测试条件的方法
即针对不同类型的属性表示属性测试条件和其对应输出的方法，通俗来讲，分裂成什么(有多路划分也有二元划分，每一个部分是什么)  
## 选择最佳划分的度量
{% qnimg 12/3.png %}  
<center>不纯度</center>

基于对不纯度的度量，进行划分。父节点的不纯程度和子女节点的不纯程度，差越大，效果越好。  
决策树归纳算法通常选择最大化**增益$\Delta$**的测试条件（即分裂的判断条件），因为I(parent)是不变的，所以等价于最小化子女节点的不纯性度量的加权平均值。  
当选择熵作为不纯性度量时，熵的差就是所谓的信息增益。  
{% qnimg 12/4.png %}  
<center>增益</center>

>对于二元属性、标称属性和连续属性的划分都运用了上述的思想，即最小化子女结点的不纯性度量。值得一提的是，连续值需要穷举确定划分点，时间复杂度大，可以进行优化。

### 增益率
我们上面提到的最小化子女结点不纯性度量。但是当我们使用使用id区分用户时，子女结点的不纯性确实降到了最小。但是显而易见，这并不是一个好的测试条件，id并不是一个有预测性的属性，我们并不希望产生大量输出的测试条件（因为与每个划分相关联的记录太少，预测不可靠）。

如何解决？  
一是限制为二元划分（如CART）；二是修改评估方式（最大化增益转变为最大化增益率gain ratio）  
<center> $$Gain\ Ratio=\frac{\Delta_{info}}{Split\  Info} $$  </center>
划分信息$\ Split\ Info=-\Sigma_{i=1}^{k}P(v_{i})log_{2}P(v_{i})$  
k代表划分总数，某个属性产生大量划分，他的划分信息将会很大。  
（顺便分享一下[如何用markdown表示数学公式](http://jzqt.github.io/2015/06/30/Markdown中写数学公式/) \ [Jekyll使用MathJax来显示数学式](http://cyukang.com/2013/03/03/try-mathjax.html)）  

## 决策树归纳算法
{% qnimg 12/5.png %}  
<center>TreeGrowth决策树归纳算法框架</center>
## 决策树归纳的特点

 1. 决策树归纳是一种构建分类模型的非参数方法（不要求任何先验假设，不假定类和其他属性服从一定的概率分布）
 2. 多采用启发式方法建立
 3. 已开发的构建决策树技术可快速建立模型。决策树一旦建立，样本分类也非常快
 4. 容易解释
 5. 是学习离散值函数的典型代表，但并不能很好的推广到某些特定的布尔问题
 6. 对于噪声干扰具有相当好的鲁棒性，特别是采用避免过分拟合方法后
 7. 冗余属性不会对决策树造成太大不利影响。不过在数据预处理阶段还是需要删除不相干属性
 8. 为了防止出现数据碎片问题，需要设置特定阈值停止分裂
 9. 子树可能在决策树中重复多次
 10. 本章之前介绍的测试条件都是每次只基于单属性，这就意味着决策边界是平行于坐标轴的直线，**限制了决策树对连续属性之间复杂关系建模的表达能力**。(斜决策树可以克服上述局限，具备更强表达能力；此外还有构造归纳法)
{% qnimg 12/6.png %}  

 11. 树剪枝的重要性比不纯性度量的选择还重要（不纯性度量方法的选择其实影响很小）

[图解决策树](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)
 
# 模型的过分拟合
训练误差（训练样本）和泛化误差（测试样本）  
拟合不足（underfitting）和过分拟合（overfitti）
>噪声（即无关属性）和多重比较过程导致过分拟合

## 泛化误差估计
### 使用再代入估计
事实上就是简单的选择最低训练误差的模型作为最终的模型，对泛化误差的估计很差
### 结合模型复杂度
简答的模型不容易过拟合,[奥卡姆剃刀(Occam's razor)](https://zh.wikipedia.org/zh-hans/奥卡姆剃刀)  
>悲观误差评估:<center>$$ e_{g}(T)=\frac{\Sigma_{i=1}^{k}[e(t_{i})+\Omega(t_{i})]}{\Sigma_{i=1}^{k}n(t_{i})}=\frac{e(T)+\Omega(T)}{N_{i}}$$  </center>
使用训练误差与模型复杂度**罚项**的和 计算泛化误差。其中n(t)是结点t分类的训练记录数，e(t)是被误分类的记录数，k是决策树的叶结点数，e(T)决策树的总训练误差，$N_{t}$是训练记录数，$\Omega(t_{i})$是每个结点$t_{i}$对应的罚项  

.
>最小描述长度原则（minimum description length，MDL）

### 估计统计上界
### 使用确认集
相当于留一部分训练样本做测试样本
## 处理决策树归纳中的过分拟合
### 先剪枝（提前终止规则）
例如增益低于阈值时就停止扩展叶结点，不过阈值难以确定
### 后剪枝
自底向上修剪

 1. 用新叶结点替换子树
 2. 用子树常用分支替换子树

# 评估分类器性能
## 保持(Holdout)方法
即常见的讲样本分为训练样本和测试样本。  
缺点:
 1. 训练集变小
 2. 模型依赖训练集和检验集的构成
 

## 随机二次抽样
多次重复保持方法，总准确率是$$acc_{sub}=\frac{\Sigma_{i=1}^{k}acc_{i}}{k}$$
## k折交叉验证(cross-validation)
除了上面那些之外还有自助法等

# 比较分类器的方法
依据数据集的大小，两个分类器准确率上的差异可能不是统计显著的（意味着仅凭准确率无法比较优劣）

两个模型得出不同的准确度，A基于30个记录检验集上的准确率达到85%，另一个B基于5000个记录检验集上的准确率达到75%，我们如何选择？

 1. 从置信区间上看
 2. 从变差上看
 
## 估计准确度的**置信区间**


[如何解释「置信区间」和「置信水平」？](https://www.zhihu.com/question/24801731/answer/251576717)

计算置信区间需要涉及正态分布，那么我们就构造正态分布，将我们的分类看成为二项式实验（每次预测的结果都是猜中与猜错），当记录个数N足够大时，可以近似用正态分布表示。
{% qnimg 12/7.png %}
> 如何理解这个式子:
中间的操作是acc减去均值再除以标准差，显而易见，这也是在求标准分（实际上，把原正态分布转化为了标准正态分布，所以下面才能直接利用z表格）；  
左右的$Z_{\alpha/2}、Z_{1-\alpha/2}$是标准分的意思，表示的是距离平均值几个标准误差，那么上面的公式就容易理解了。
标准分的概念和标准正态分布息息相关。

通过整体，可以化为下面的表达式
{% qnimg 12/8.png %}
那么，基于检验记录，测得的准确率，置信水平，查表，代入公式就能求得置信区间（所谓区间就是一个范围，这里由于accuracy本来就是一个百分数，所以区间当然也用百分数表示，不要混淆）

综上，在给定置信水平的情况下，通过比较置信区间，对于两个模型A、B的优劣就有定调了。

## 比较两个模型的性能（模型不同不意味分类法不同）

> 补充一下相关方面的知识  
[假设检验与统计显著--马同学在知乎的回答](https://www.zhihu.com/question/23149768/answer/282842210)  
[假设检验与统计显著--猴子在知乎的回答](https://www.zhihu.com/question/20254932/answer/375134218)  
[单侧检验和双侧检验](http://book.51cto.com/art/201205/337283.htm)


这里的目的是检验两个模型的错误率（或准确率）的观察差（实际检测得到的）是否是统计显著的（先大致认为统计学意义上真的有差别，而不只是波动或抽样导致的）  
举个比较狭义的例子，两个模型得出的准确率相差0.05%，他们实际上是不是真的有差异？

通过两个模型的检验记录数、错误率，我们可以计算出在特定的置信水平p下，其实际差（实际准确率的差值）的置信区间是否包含了0，若包含，那可以断言在P的置信水平下，该观察差（测得的准确率差值）不是统计显著的（即认为在p的置信水平下，我们不认为基于这些样本这两个模型体现出来的精度差是真实有效的）

PS：建议看一下教材这里讲解用的题例

## 比较两种分类法的性能
> 建议看教材题例
 
基本思路与上面比较两个模型的性能相同：

 1. 假设足够大，得两模型正态分布
 2. 合并得观察差的正态分布（观测差d，服从均值为实际值、方差为$\sigma^{2}$的正态分布，而方差往往由前面得出的两个正态分布推出）
 3. 计算特定置信水平下的置信区间（注意计算置信区间是基于观测差的，所以其中心是观测差）
 4. 若区间包含0，则观察差不是统计显著的

采用的是KFold交叉验证，同样是得出第j折的准确率差$d_{j}$服从均值为真实差、方差为$\sigma^{2}$的正态分布。不同的是最后利用t分布求出置信区间。

t分布以后再讲，先介绍一下[中心极限定理与大数定律](https://www.zhihu.com/question/22913867/answer/250046834)
>中心极限定理：  
样本的平均值约等于总体的平均值。
不管总体是什么分布，任意一个总体的样本平均值都会围绕在总体的整体平均值周围，并且呈正态分布。